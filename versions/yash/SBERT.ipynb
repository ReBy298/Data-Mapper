{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (3.3.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from sentence-transformers) (4.46.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from sentence-transformers) (4.67.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from sentence-transformers) (0.26.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (3.3.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (4.46.2)\n",
      "Requirement already satisfied: torch in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from sentence-transformers) (4.67.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from sentence-transformers) (0.26.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade sentence-transformers transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from matplotlib) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (0.13.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from seaborn) (2.1.3)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yasvanth.pamidi\\onedrive - encora\\desktop\\vsc\\myenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load csv files\n",
    "df1 = pd.read_csv(r\"C:\\Users\\Yasvanth.Pamidi\\OneDrive - ENCORA\\Desktop\\DataMap\\LHS.csv\") #path to file1\n",
    "df2 = pd.read_csv(r\"C:\\Users\\Yasvanth.Pamidi\\OneDrive - ENCORA\\Desktop\\DataMap\\RHS.csv\") #path to file2\n",
    "\n",
    "#df1 = pd.read_csv(file1)\n",
    "#df2 = pd.read_csv(file2)\n",
    "\n",
    "#define columns to compare\n",
    "column1 = 'Description' #column name in df1\n",
    "column2 = 'Description' #column name in df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the third row as the header and select the third column\n",
    "#df2.columns = df2.iloc[2]  # Set the third row as the header\n",
    "#selected_column = df2.iloc[3:, 2]  # Select data starting from the fourth row in the third column\n",
    "\n",
    "# Display the selected column\n",
    "#print(selected_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "HFValidationError",
     "evalue": "Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: 'C:\\Users\\Yasvanth.Pamidi\\OneDrive - ENCORA\\Desktop\\paraphrase-mpnet-base-v2'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Yasvanth.Pamidi\\OneDrive - ENCORA\\Desktop\\VSC\\myenv\\Lib\\site-packages\\sentence_transformers\\util.py:1395\u001b[0m, in \u001b[0;36mload_dir_path\u001b[1;34m(model_name_or_path, directory, token, cache_folder, revision, local_files_only)\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1395\u001b[0m     repo_path \u001b[38;5;241m=\u001b[39m \u001b[43msnapshot_download\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdownload_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1396\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1397\u001b[0m     \u001b[38;5;66;03m# Otherwise, try local (i.e. cache) only\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Yasvanth.Pamidi\\OneDrive - ENCORA\\Desktop\\VSC\\myenv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 106\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Yasvanth.Pamidi\\OneDrive - ENCORA\\Desktop\\VSC\\myenv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:160\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[1;34m(repo_id)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n\u001b[1;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must use alphanumeric chars or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m are\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m forbidden, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m cannot start or end the name, max length is 96:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    163\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    164\u001b[0m     )\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id:\n",
      "\u001b[1;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: 'C:\\Users\\Yasvanth.Pamidi\\OneDrive - ENCORA\\Desktop\\paraphrase-mpnet-base-v2'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[138], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Automatically download and load the model\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mYasvanth.Pamidi\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mOneDrive - ENCORA\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDesktop\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mparaphrase-mpnet-base-v2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Yasvanth.Pamidi\\OneDrive - ENCORA\\Desktop\\VSC\\myenv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:308\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[1;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[0m\n\u001b[0;32m    299\u001b[0m         model_name_or_path \u001b[38;5;241m=\u001b[39m __MODEL_HUB_ORGANIZATION__ \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m model_name_or_path\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sentence_transformer_model(\n\u001b[0;32m    302\u001b[0m     model_name_or_path,\n\u001b[0;32m    303\u001b[0m     token,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    306\u001b[0m     local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    307\u001b[0m ):\n\u001b[1;32m--> 308\u001b[0m     modules, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_sbert_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    320\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_auto_model(\n\u001b[0;32m    321\u001b[0m         model_name_or_path,\n\u001b[0;32m    322\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    329\u001b[0m         config_kwargs\u001b[38;5;241m=\u001b[39mconfig_kwargs,\n\u001b[0;32m    330\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Yasvanth.Pamidi\\OneDrive - ENCORA\\Desktop\\VSC\\myenv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1736\u001b[0m, in \u001b[0;36mSentenceTransformer._load_sbert_model\u001b[1;34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m         module_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m         module_path \u001b[38;5;241m=\u001b[39m \u001b[43mload_dir_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodule_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m     module \u001b[38;5;241m=\u001b[39m module_class\u001b[38;5;241m.\u001b[39mload(module_path)\n\u001b[0;32m   1746\u001b[0m modules[module_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m module\n",
      "File \u001b[1;32mc:\\Users\\Yasvanth.Pamidi\\OneDrive - ENCORA\\Desktop\\VSC\\myenv\\Lib\\site-packages\\sentence_transformers\\util.py:1399\u001b[0m, in \u001b[0;36mload_dir_path\u001b[1;34m(model_name_or_path, directory, token, cache_folder, revision, local_files_only)\u001b[0m\n\u001b[0;32m   1396\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1397\u001b[0m     \u001b[38;5;66;03m# Otherwise, try local (i.e. cache) only\u001b[39;00m\n\u001b[0;32m   1398\u001b[0m     download_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_files_only\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 1399\u001b[0m     repo_path \u001b[38;5;241m=\u001b[39m \u001b[43msnapshot_download\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdownload_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1400\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(repo_path, directory)\n",
      "File \u001b[1;32mc:\\Users\\Yasvanth.Pamidi\\OneDrive - ENCORA\\Desktop\\VSC\\myenv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arg_name, arg_value \u001b[38;5;129;01min\u001b[39;00m chain(\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28mzip\u001b[39m(signature\u001b[38;5;241m.\u001b[39mparameters, args),  \u001b[38;5;66;03m# Args values\u001b[39;00m\n\u001b[0;32m    103\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mitems(),  \u001b[38;5;66;03m# Kwargs values\u001b[39;00m\n\u001b[0;32m    104\u001b[0m ):\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 106\u001b[0m         \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    109\u001b[0m         has_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Yasvanth.Pamidi\\OneDrive - ENCORA\\Desktop\\VSC\\myenv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:160\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[1;34m(repo_id)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be in the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace/repo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use `repo_type` argument if needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    157\u001b[0m     )\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n\u001b[1;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must use alphanumeric chars or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m are\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m forbidden, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m cannot start or end the name, max length is 96:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    163\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    164\u001b[0m     )\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id:\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have -- or .. in repo_id: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: 'C:\\Users\\Yasvanth.Pamidi\\OneDrive - ENCORA\\Desktop\\paraphrase-mpnet-base-v2'."
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Automatically download and load the model\n",
    "model = SentenceTransformer(r\"C:\\Users\\Yasvanth.Pamidi\\OneDrive - ENCORA\\Desktop\\paraphrase-mpnet-base-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name C:\\Users\\Yasvanth.Pamidi\\OneDrive - ENCORA\\Desktop\\DataMap\\paraphrase-mpnet-base-v2. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "#initialize SBERT model\n",
    "#model = SentenceTransformer('sentence-transformers/paraphrase-Mpnet-base-v2')\n",
    "\n",
    "\n",
    "model = SentenceTransformer(r\"C:\\Users\\Yasvanth.Pamidi\\OneDrive - ENCORA\\Desktop\\DataMap\\paraphrase-mpnet-base-v2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 8/8 [00:02<00:00,  2.86it/s]\n",
      "Batches:  94%|█████████▍| 15/16 [00:08<00:00,  1.72it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Generate Embeddings for each sentense in the selected columns\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#top 10 rows\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#embeddings for selected rows\u001b[39;00m\n\u001b[0;32m     10\u001b[0m embeddings1 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(df1[column1]\u001b[38;5;241m.\u001b[39mto_list(), show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,convert_to_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 11\u001b[0m embeddings2 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn2\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Yasvanth.Pamidi\\OneDrive - ENCORA\\Desktop\\VSC\\myenv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:591\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[1;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start_index \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(sentences), batch_size, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatches\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n\u001b[0;32m    590\u001b[0m     sentences_batch \u001b[38;5;241m=\u001b[39m sentences_sorted[start_index : start_index \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[1;32m--> 591\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    592\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    593\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n",
      "File \u001b[1;32mc:\\Users\\Yasvanth.Pamidi\\OneDrive - ENCORA\\Desktop\\VSC\\myenv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1050\u001b[0m, in \u001b[0;36mSentenceTransformer.tokenize\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Tensor]:\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;124;03m    Tokenizes the texts.\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;124;03m            \"attention_mask\", and \"token_type_ids\".\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1050\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_first_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Yasvanth.Pamidi\\OneDrive - ENCORA\\Desktop\\VSC\\myenv\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:437\u001b[0m, in \u001b[0;36mTransformer.tokenize\u001b[1;34m(self, texts, padding)\u001b[0m\n\u001b[0;32m    435\u001b[0m batch1, batch2 \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text_tuple \u001b[38;5;129;01min\u001b[39;00m texts:\n\u001b[1;32m--> 437\u001b[0m     batch1\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtext_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m    438\u001b[0m     batch2\u001b[38;5;241m.\u001b[39mappend(text_tuple[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    439\u001b[0m to_tokenize \u001b[38;5;241m=\u001b[39m [batch1, batch2]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "#Generate Embeddings for each sentense in the selected columns\n",
    "\n",
    "#top 10 rows\n",
    "#top10_df1 = df1[column1].head(10)\n",
    "#top10_df2 = df2[column2].head(10)\n",
    "\n",
    "\n",
    "\n",
    "#embeddings for selected rows\n",
    "embeddings1 = model.encode(df1[column1].to_list(), show_progress_bar=True,convert_to_tensor=True)\n",
    "embeddings2 = model.encode(df2[column2].to_list(), show_progress_bar=True,convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings1.shape\n",
    "embeddings2.shape\n",
    "embeddings1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the cosine_similarity_matrix\n",
    "\n",
    "similarity_matrix = util.cos_sim(embeddings1,embeddings2).cpu().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'corpus_id': 115, 'score': 0.44968175888061523},\n",
       " {'corpus_id': 401, 'score': 0.35248929262161255},\n",
       " {'corpus_id': 259, 'score': 0.34406495094299316},\n",
       " {'corpus_id': 359, 'score': 0.33600741624832153},\n",
       " {'corpus_id': 110, 'score': 0.33227336406707764},\n",
       " {'corpus_id': 269, 'score': 0.32963380217552185},\n",
       " {'corpus_id': 409, 'score': 0.32397496700286865},\n",
       " {'corpus_id': 157, 'score': 0.3159094750881195},\n",
       " {'corpus_id': 78, 'score': 0.3107191026210785},\n",
       " {'corpus_id': 132, 'score': 0.30831384658813477}]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = util.semantic_search(embeddings1[0],embeddings2)[0]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize similarity matrix as heatmap\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(similarity_matrix, annot=True, fmt=\".2f\", cmap='viridis', cbar=True)\n",
    "plt.title(\"Cosine Similarity Matrix\")\n",
    "plt.xlabel(\"Sentences from column 2\")\n",
    "plt.ylabel(\"sentences from column 1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Highest Similarities:\n",
      "\n",
      "Description in df1 (row 128): Expiration Date\n",
      "Description in df2 (row 31): nan\n",
      "Similarity Score: 0.8142386078834534\n",
      "\n",
      "Description in df1 (row 31): Weight Unit\n",
      "Description in df2 (row 284): The minimum required shelf life of an item once it's delivered to the store at ambient, refrigerated and frozen temperatures (will be different at each temperature) . One of these will be trreated as recommended temperature\n",
      "Similarity Score: 0.8123611211776733\n",
      "\n",
      "Description in df1 (row 31): Weight Unit\n",
      "Description in df2 (row 283): The shelf life of an item after production at ambient, refrigerated and frozen temperatures (will be different for each temperature\n",
      "Similarity Score: 0.8123611211776733\n",
      "\n",
      "Bottom 3 Lowest Similarities:\n",
      "\n",
      "Description in df1 (row 197): NATO Stock Number\n",
      "Description in df2 (row 275): Temperature at which the item is stored (e.g. embient, frozen, refrigerated) in the DC\n",
      "Similarity Score: -0.14703693985939026\n",
      "\n",
      "Description in df1 (row 197): NATO Stock Number\n",
      "Description in df2 (row 276): Temperature at which the item is shipped out to stores (e.g. embient, frozen, refrigerated)\n",
      "Similarity Score: -0.14703693985939026\n",
      "\n",
      "Description in df1 (row 198): Spare Part Class Code\n",
      "Description in df2 (row 184): GTIN of each\n",
      "Similarity Score: -0.13434919714927673\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Flatten the similarity matrix and get sorted indices\n",
    "flat_similarity_matrix = similarity_matrix.flatten()\n",
    "sorted_indices = np.argsort(flat_similarity_matrix)\n",
    "\n",
    "# Get the indices of the top 3 highest and bottom 3 lowest similarity values\n",
    "top_3_indices = sorted_indices[-3:][::-1]  # Top 3 in descending order\n",
    "bottom_3_indices = sorted_indices[:3]      # Bottom 3 in ascending order\n",
    "\n",
    "# Function to get row, column index from the flattened index\n",
    "def get_indices(flat_index, shape):\n",
    "    return np.unravel_index(flat_index, shape)\n",
    "\n",
    "# Display Top 3 highest similarities\n",
    "print(\"Top 3 Highest Similarities:\")\n",
    "for index in top_3_indices:\n",
    "    row, col = get_indices(index, similarity_matrix.shape)\n",
    "    print(f\"\\nDescription in df1 (row {row}): {df1[column1].iloc[row]}\")\n",
    "    print(f\"Description in df2 (row {col}): {df2[column2].iloc[col]}\")\n",
    "    print(f\"Similarity Score: {similarity_matrix[row, col]}\")\n",
    "\n",
    "# Display Bottom 3 lowest similarities\n",
    "print(\"\\nBottom 3 Lowest Similarities:\")\n",
    "for index in bottom_3_indices:\n",
    "    row, col = get_indices(index, similarity_matrix.shape)\n",
    "    print(f\"\\nDescription in df1 (row {row}): {df1[column1].iloc[row]}\")\n",
    "    print(f\"Description in df2 (row {col}): {df2[column2].iloc[col]}\")\n",
    "    print(f\"Similarity Score: {similarity_matrix[row, col]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Sentence: Expiration Date\n",
      "Sentence index in embeddings2: 31, Similarity: 0.8142386078834534\n",
      "Sentence index in embeddings2: 72, Similarity: 0.6345313787460327\n",
      "Sentence index in embeddings2: 79, Similarity: 0.6288743019104004\n",
      "Top 3 most similar sentences: [nan, 'The WAWA employee Id acting as the primary contact for the item/Product', '4. Seasonal Suspend']\n"
     ]
    }
   ],
   "source": [
    "# Select a specific sentence from embeddings1, e.g., the first sentence (index 0)\n",
    "selected_index = 128\n",
    "similarities = similarity_matrix[selected_index]  # Get similarity scores for the selected sentence\n",
    "\n",
    "# Find the indices of the top 3 most similar sentences in embeddings2\n",
    "top_3_indices = np.argsort(similarities)[-3:][::-1]  # Sort and get indices in descending order\n",
    "\n",
    "#print the actual sentence\n",
    "print('Actual Sentence: '+df1[column1][selected_index])\n",
    "\n",
    "# Print the top 3 indices and their similarity scores\n",
    "for idx in top_3_indices:\n",
    "    print(f\"Sentence index in embeddings2: {idx}, Similarity: {similarities[idx]}\")\n",
    "\n",
    "# Example: If you want to retrieve the actual sentences, ensure you have access to the original sentences.\n",
    "# embeddings2_sentences is assumed to be the list of sentences corresponding to embeddings2\n",
    "top_3_sentences = [df2[column2][idx] for idx in top_3_indices]\n",
    "print(\"Top 3 most similar sentences:\", top_3_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"results\": [\n",
      "    {\n",
      "      \"lhs_desc_0\": \"Client\",\n",
      "      \"matches\": [\n",
      "        {\n",
      "          \"rhs_field_desc_1\": \"Lowest parent leve for Menu category (navigational hierarechy )\",\n",
      "          \"rhs_field_score\": 0.44968175888061523\n",
      "        },\n",
      "        {\n",
      "          \"rhs_field_desc_2\": \"no substance added that imparts color to a food that is derived from a synthetic substance.\",\n",
      "          \"rhs_field_score\": 0.35248929262161255\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"lhs_desc_1\": \"Material Number\",\n",
      "      \"matches\": [\n",
      "        {\n",
      "          \"rhs_field_desc_1\": \"Effective End  date\",\n",
      "          \"rhs_field_score\": 0.560577392578125\n",
      "        },\n",
      "        {\n",
      "          \"rhs_field_desc_2\": \"The quantity of each component item in a shipper display\",\n",
      "          \"rhs_field_score\": 0.5381794571876526\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"lhs_desc_2\": \"Created On\",\n",
      "      \"matches\": [\n",
      "        {\n",
      "          \"rhs_field_desc_1\": \"Uses fish in manufacture \",\n",
      "          \"rhs_field_score\": 0.3384504020214081\n",
      "        },\n",
      "        {\n",
      "          \"rhs_field_desc_2\": \"1 Family code(tobacco)\",\n",
      "          \"rhs_field_score\": 0.33561018109321594\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"lhs_desc_3\": \"Name of Person who Created the Object\",\n",
      "      \"matches\": [\n",
      "        {\n",
      "          \"rhs_field_desc_1\": \"The physical location of the code on the master case of product\",\n",
      "          \"rhs_field_score\": 0.41159123182296753\n",
      "        },\n",
      "        {\n",
      "          \"rhs_field_desc_2\": \"Product ID defined by the MDM system\",\n",
      "          \"rhs_field_score\": 0.3395150303840637\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"lhs_desc_4\": \"Date of Last Change\",\n",
      "      \"matches\": [\n",
      "        {\n",
      "          \"rhs_field_desc_1\": NaN,\n",
      "          \"rhs_field_score\": 0.6233363151550293\n",
      "        },\n",
      "        {\n",
      "          \"rhs_field_desc_2\": \"Defines the base quantity numeric value for measuring the Item &  Ingredient . All measures are reflected as a multiple of this quantity . Base quantity for brisket is 2.497 OZ. \",\n",
      "          \"rhs_field_score\": 0.5164742469787598\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"lhs_desc_5\": \"Name of Person Who Changed Object\",\n",
      "      \"matches\": [\n",
      "        {\n",
      "          \"rhs_field_desc_1\": \"The physical location of the code on the master case of product\",\n",
      "          \"rhs_field_score\": 0.42247411608695984\n",
      "        },\n",
      "        {\n",
      "          \"rhs_field_desc_2\": \"% Daily Value of Vitamin A per 100g of product \",\n",
      "          \"rhs_field_score\": 0.3292621970176697\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"lhs_desc_6\": \"Maintenance status of complete material\",\n",
      "      \"matches\": [\n",
      "        {\n",
      "          \"rhs_field_desc_1\": \"gram weight of serving size \",\n",
      "          \"rhs_field_score\": 0.45680201053619385\n",
      "        },\n",
      "        {\n",
      "          \"rhs_field_desc_2\": \"Uses soy  in manufacture \",\n",
      "          \"rhs_field_score\": 0.4406208395957947\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"lhs_desc_7\": \"Maintenance status\",\n",
      "      \"matches\": [\n",
      "        {\n",
      "          \"rhs_field_desc_1\": \"gram weight of serving size \",\n",
      "          \"rhs_field_score\": 0.5861552357673645\n",
      "        },\n",
      "        {\n",
      "          \"rhs_field_desc_2\": \"Standardized name of the product  as represented in MDM.Inherit from \\\"Item Long name\\\" for FPS. For other types , the user need to enter it.\",\n",
      "          \"rhs_field_score\": 0.37985944747924805\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"lhs_desc_8\": \"Flag Material for Deletion at Client Level\",\n",
      "      \"matches\": [\n",
      "        {\n",
      "          \"rhs_field_desc_1\": \"per FDA nutrient content claim standards \",\n",
      "          \"rhs_field_score\": 0.5659593343734741\n",
      "        },\n",
      "        {\n",
      "          \"rhs_field_desc_2\": \"Indicates if there is a restriction on purchasing the product\",\n",
      "          \"rhs_field_score\": 0.34065404534339905\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"lhs_desc_9\": \"Material Type\",\n",
      "      \"matches\": [\n",
      "        {\n",
      "          \"rhs_field_desc_1\": \"Vitamin E Amoung in milligrams per 100g of product \",\n",
      "          \"rhs_field_score\": 0.49877387285232544\n",
      "        },\n",
      "        {\n",
      "          \"rhs_field_desc_2\": \"Uses eggs  in manufacture \",\n",
      "          \"rhs_field_score\": 0.49877387285232544\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Function to retrieve top-N most similar sentences for all sentences in embeddings1\n",
    "def retrieve_top_similar_sentences_json(num_sentences, top_n):\n",
    "    results = []  # List to hold all results\n",
    "\n",
    "    for selected_index in range(num_sentences):\n",
    "        # Get similarity scores for the selected sentence\n",
    "        similarities = similarity_matrix[selected_index]\n",
    "\n",
    "        # Find the indices of the top N most similar sentences in embeddings2\n",
    "        top_indices = np.argsort(similarities)[-top_n:][::-1]  # Sort in descending order\n",
    "\n",
    "        # Construct matches\n",
    "        matches = []\n",
    "        for rank, idx in enumerate(top_indices, start=1):\n",
    "            matches.append({\n",
    "                f\"rhs_field_desc_{rank}\": df2[column2][idx],\n",
    "                \"rhs_field_score\": float(similarities[idx])  # Convert to native Python float\n",
    "            })\n",
    "\n",
    "        # Construct the result for the current LHS sentence\n",
    "        result = {\n",
    "          #  f\"lhs_field_{selected_index}\": df1[column1][selected_index],\n",
    "            f\"lhs_desc_{selected_index}\": df1[column1][selected_index],\n",
    "            \"matches\": matches\n",
    "        }\n",
    "\n",
    "        # Append to results\n",
    "        results.append(result)\n",
    "\n",
    "    # Format as JSON\n",
    "    final_output = {\"results\": results}\n",
    "    return final_output\n",
    "\n",
    "# User inputs: number of sentences to process and top-N similarities to retrieve\n",
    "num_sentences_to_process = int(input(\"Enter the number of sentences from LHS to process: \") or len(df1))\n",
    "top_n = int(input(\"Enter the number of top similar sentences to retrieve (N): \") or 3)\n",
    "\n",
    "# Retrieve results in the specified JSON format\n",
    "output_json = retrieve_top_similar_sentences_json(num_sentences_to_process, top_n)\n",
    "\n",
    "# Print the output as formatted JSON\n",
    "print(json.dumps(output_json, indent=2))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
